{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.set_printoptions(edgeitems=2, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio.v2 as imageio  # Use version 2 API\n",
    "img_arr = imageio.imread('../data/p1ch4/image-dog/bobby.jpg')\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.from_numpy()` creates a tensor that shares the same underlying memory as the NumPy array, meaning modifications to img will also affect img_arr (and vice versa).\\\n",
    "`permute(2, 0, 1)` reorders these dimensions to (channels, height, width), resulting in a shape of (3, 720, 1280).\n",
    "This is a common convention in PyTorch for image data, where neural networks (e.g., convolutional layers) expect the channel dimension first (e.g., C x H x W instead of H x W x C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.from_numpy(img_arr)\n",
    "out = img.permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a list `filenames` containing the names of all files in `data_dir` that end with `.png`.\\\n",
    "`os.listdir(data_dir)`: Lists all files and directories in data_dir.\\\n",
    "`os.path.splitext(name)`: Splits a filename into its base name and extension (e.g., 'cat.png' becomes ('cat', '.png')).\\\n",
    "`[-1]`: Takes the extension part (e.g., .png).\\\n",
    "The list comprehension filters for files with the .png extension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = '../data/p1ch4/image-cats/'\n",
    "filenames = [name for name in os.listdir(data_dir)\n",
    "             if os.path.splitext(name)[-1] == '.png']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`enumerate(filenames)` provides both an index i (starting at 0) and the corresponding filename.\\\n",
    "Since batch_size is 3, the loop will process up to 3 images (assuming there are at least 3 PNG files).\\\n",
    "When we apply img_t[:3], the slicing operates on the first dimension of the tensor (index 0). In PyTorch (and Python generally), the syntax [:3] means “take all elements from the start up to (but not including) the 3rd index along this dimension.” Since the first dimension is now the channel dimension with a size of 3, img_t[:3] selects: Channel 0 (e.g., Red), Channel 1 (e.g., Green), Channel 2 (e.g., Blue).\\\n",
    "Assigns the processed tensor img_t to the i-th position in the batch tensor.\n",
    "\n",
    "`batch[i] = img_t`: batch has shape (3, 3, 256, 256), so `img_t` must have shape (3, 256, 256) to fit. This assumes all images are 256x256 pixels; otherwise, resizing would be needed (not shown here).\n",
    "\n",
    "What if I want the slicing to operate on the second dimension of the tensor?\n",
    "First 100 elements: `tensor[:, :100, :]` → shape (3, 100, 256).\n",
    "\n",
    "What if I want the slicing to operate on the third dimension of the tensor?\n",
    "Let’s say your tensor has shape (3, 256, 256) (3 channels, 256 height, 256 width).\\\n",
    "`tensor[:, :, :100]`\n",
    "\n",
    "# Can I Use `tensor[:, :100]` Instead of `tensor[:, :100, :]` for a 3D Tensor of Shape `(3, 256, 256)`?\n",
    "\n",
    "Yes, you can use `tensor[:, :100]` rather than `tensor[:, :100, :]` for a 3D tensor of shape `(3, 256, 256)` in PyTorch, and both will produce the same result.\n",
    "\n",
    "## Why It Works\n",
    "\n",
    "In PyTorch, tensor slicing follows the format `tensor[dim0_slice, dim1_slice, dim2_slice, ...]`, where each slice corresponds to one of the tensor’s dimensions. For a 3D tensor with shape `(3, 256, 256)`:\n",
    "- The first dimension (size 3) typically represents channels or some similar grouping.\n",
    "- The second dimension (size 256) represents the height.\n",
    "- The third dimension (size 256) represents the width.\n",
    "\n",
    "### Breaking Down the Slicing\n",
    "\n",
    "- **`tensor[:, :100, :]`**:\n",
    "  - `:` in the first position means \"select all elements of the first dimension\" (all 3 channels).\n",
    "  - `:100` in the second position means \"select the first 100 elements of the second dimension\" (the first 100 rows out of 256).\n",
    "  - `:` in the third position means \"select all elements of the third dimension\" (all 256 columns).\n",
    "  - Resulting shape: `(3, 100, 256)`.\n",
    "\n",
    "- **`tensor[:, :100]`**:\n",
    "  - When you provide fewer slices than the number of dimensions in PyTorch, the remaining dimensions are implicitly sliced with `:` (select all).\n",
    "  - So, `tensor[:, :100]` is interpreted as `tensor[:, :100, :]`.\n",
    "  - This means:\n",
    "    - `:` selects all 3 elements of the first dimension.\n",
    "    - `:100` selects the first 100 elements of the second dimension.\n",
    "    - (Implicit) `:` selects all 256 elements of the third dimension.\n",
    "  - Resulting shape: `(3, 100, 256)`.\n",
    "\n",
    "### Why They’re Equivalent\n",
    "\n",
    "In both cases, the slicing selects:\n",
    "- All channels (3),\n",
    "- The first 100 rows (out of 256),\n",
    "- All columns (256).\n",
    "\n",
    "Thus, both `tensor[:, :100]` and `tensor[:, :100, :]` result in a tensor with the same shape, `(3, 100, 256)`, and contain the same data. This behavior is consistent with how PyTorch (and NumPy) handles slicing: if fewer indices are provided than the tensor’s number of dimensions, the unspecified dimensions are fully selected by default.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "For a 3D tensor of shape `(3, 256, 256)`, `tensor[:, :100]` is a valid shorthand for `tensor[:, :100, :]` and achieves the exact same outcome. You can use either form interchangeably in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2, 0, 1)\n",
    "    img_t = img_t[:3]\n",
    "    batch[i] = img_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the values of the pixels by 255 (the maximum representable number in 8-bit unsigned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.float()\n",
    "batch /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This extracts the number of channels from batch’s shape.\\\n",
    "`batch.shape` is (3, 3, 256, 256), so `batch.shape[1]` is 3 (the channel dimension).\\\n",
    "`n_channels` is set to 3, representing the RGB channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = batch.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`batch[:, c]` selects the c-th channel for all images in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:, c])\n",
    "    std = torch.std(batch[:, c])\n",
    "    batch[:, c] = (batch[:, c] - mean) / std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "We discovered that several entries in the `candidates.csv` file appear multiple times. These repeated entries are not exact duplicates, which suggests that the original annotations made by human experts were not properly cleaned before being added to the file. For example, some entries might refer to the same lung nodule, but appear in different CT image slices. Interestingly, these types of variations might actually be helpful for training our classifier, since they provide multiple views of the same object.\n",
    "\n",
    "To address this issue, we have prepared a cleaned version of the `annotation.csv` file. The LUNA dataset we are using is based on a more comprehensive dataset called the Lung Image Database Consortium Image Collection (LIDC-IDRI). This original dataset includes detailed annotations from multiple radiologists.\n",
    "\n",
    "This script is used to extract the original LIDC annotations, identify the actual nodules, remove redundant or duplicate entries, and save the cleaned data to a file named `annotations_with_malignancy.csv`\n",
    "\n",
    "Using this new file, we can now use our `getCandidateInfoList function` defined in `dsets.py` to extract nodules based on the improved annotation data. This involves iterating over each new annotation, identifying the nodules, and then using a CSV reader to load the data. During this process, we convert the data into the appropriate data types and store it in a structure called `CandidateInfoTuple`.\n",
    "\n",
    "\n",
    "\n",
    "# Purpose: Data Cleansing\n",
    "- This script processes lung CT scan annotation data to enrich it with malignancy information derived from the LIDC-IDRI dataset.\n",
    "- It also converts raw annotation data into a structured format (DataFrame) for improved accessibility, analysis, and modeling.\n",
    "\n",
    "Key Objectives:\n",
    "1. **Data Integration**:\n",
    "  - Load LUNA challenge annotations (`annotations.csv`).\n",
    "  - Extract scan and malignancy metadata using PyLIDC.\n",
    "\n",
    "2. **Malignancy Computation**:\n",
    "  - Determine malignancy for each nodule cluster.\n",
    "  - Convert pixel coordinates to physical space using SimpleITK for spatial accuracy.\n",
    "\n",
    "3. **Annotation Matching**:\n",
    "  - Match PyLIDC-derived malignancy nodules to LUNA annotations based on centroid proximity.\n",
    "  - Enrich the LUNA annotations with malignancy label (`mal_bool`), details (`mal_details`), and bounding box information.\n",
    "\n",
    "4. **Data Cleansing**:\n",
    "  - Drop annotations that could not be matched to PyLIDC data or CT volumes.\n",
    "  - Save the cleaned and enhanced annotation data as `annotations_with_malignancy.csv`.\n",
    "\n",
    "## Why This Matters:\n",
    "Accurate malignancy labeling is crucial for training robust medical imaging models. This preprocessing step ensures the training data includes high-quality, expert-derived labels while filtering out unmatched or incomplete records.\n",
    "\n",
    "Output:\n",
    "- `annotations_with_malignancy.csv`: A refined annotation dataset with malignancy labels for downstream deep learning pipelines.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import SimpleITK as sitk\n",
    "import pandas\n",
    "import glob, os\n",
    "import numpy\n",
    "import tqdm\n",
    "import pylidc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the annotations from the LUNA challenge. The `annotations` variable is a DataFrame (table) containing nodule annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pandas.read_csv('data/part2/luna/annotations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "For the CTs where we have a `.mhd` file, we collect the malignancy_data from PyLIDC.\n",
    "\n",
    "It is a bit tedious as we need to convert the pixel locations provided by PyLIDC to physical points.\n",
    "We will see some warnings about annotations to be too close too each other (PyLIDC expects to have 4 annotations per site, including when we consider a nodule to be malignant).\n",
    "\n",
    "This takes quite a while (~1-2 seconds per scan on the author's computer).\n",
    "\n",
    "Cluster is a group of annotations (by different radiologists) that are close enough to refer to the same physical nodule.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Why there are **multiple malignancy scores** per `ann_cluster`\n",
    "\n",
    "In the **LUNA16 dataset** (used with `pylidc`), each **nodule (tumor candidate)** is often **independently annotated by multiple radiologists** ‚Äî typically 4 different doctors.\n",
    "\n",
    "Each radiologist:\n",
    "\n",
    "* Views the same scan.\n",
    "* Finds the same nodule.\n",
    "* Assigns a **malignancy score** from 1 to 5:\n",
    "\n",
    "  * 1 = highly benign\n",
    "  * 5 = highly malignant\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ What is an `ann_cluster`?\n",
    "\n",
    "An `ann_cluster` is a group of annotations that refer to the **same physical nodule**, made by different radiologists.\n",
    "\n",
    "So, if four radiologists each mark the same nodule, the cluster will contain **4 annotation objects**, each with its own:\n",
    "\n",
    "* `centroid` (center)\n",
    "* `bbox_matrix()` (bounding box)\n",
    "* `malignancy` score\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Why do we use multiple scores?\n",
    "\n",
    "1. **Inter-rater variation**: Doctors may disagree.\n",
    "2. **Reduce noise**: Instead of trusting one opinion, we average or vote.\n",
    "3. **Robustness**: By requiring \"at least two scores ‚â• 4\", the code ensures that the **nodule is likely malignant**, not due to one outlier opinion.\n",
    "\n",
    "We consider a cluster of annotations to be malignant (i.e., cancerous) if at least two of the radiologists who marked that nodule gave it a high malignancy score.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                       | 69/601 [00:47<06:27,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                    | 93/601 [01:04<06:33,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                 | 107/601 [01:13<06:07,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                  | 225/601 [02:42<05:34,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                            | 267/601 [03:13<03:23,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                          | 281/601 [03:22<03:42,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 368/601 [04:25<02:39,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 435/601 [05:11<02:19,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 446/601 [05:20<01:32,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 450/601 [05:22<01:48,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 527/601 [06:08<00:41,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 577/601 [06:39<00:20,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 597/601 [06:53<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 601/601 [06:55<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Monkey patch for compatibility with old versions of pylidc using deprecated np.int\n",
    "if not hasattr(np, 'int'):\n",
    "    np.int = int\n",
    "\n",
    "# Each item will contain a tumor's 3D position, bounding box, and malignancy.\n",
    "malignancy_data = []\n",
    "# Track any scan files that could not be found.\n",
    "missing = []\n",
    "# Store the pixel spacing for each scan ‚Äî how much physical space each voxel represents\n",
    "spacing_dict = {}\n",
    "\n",
    "# Loads all available CT scans using pylidc, mapping each scan‚Äôs unique ID to its scan object.\n",
    "# The keys are each scan‚Äôs unique ID. The values are the scan objects themselves.\n",
    "scans = {s.series_instance_uid: s for s in pylidc.query(pylidc.Scan).all()}\n",
    "\n",
    "# Access the column named seriesuid, which stores the scan ID each annotation belongs to.\n",
    "# Then, extract all distinct values (i.e., removes duplicates).\n",
    "# Finally, store those unique scan IDs in the variable suids.\n",
    "suids = annotations.seriesuid.unique()\n",
    "\n",
    "# Loop over each scan ID, with a progress bar from tqdm.\n",
    "for suid in tqdm.tqdm(suids):\n",
    "    # fn is a list of filenames (file paths), found using a wildcard pattern.\n",
    "    fn = glob.glob('F:/Organized_LUNA16_Train_Data/subset*/{}.mhd'.format(suid))\n",
    "    if len(fn) == 0 or '*' in fn[0]:\n",
    "        missing.append(suid)\n",
    "        continue\n",
    "    fn = fn[0]\n",
    "    x = sitk.ReadImage(fn) # Load the image\n",
    "    spacing_dict[suid] = x.GetSpacing() #Get voxel spacing\n",
    "    s = scans[suid]\n",
    "    \n",
    "    # s.cluster_annotations() groups multiple annotations into clusters. Each cluster represents one real-world nodule.\n",
    "    for ann_cluster in s.cluster_annotations():\n",
    "        # A cluster (a set of annotations referring to the same nodule) is considered malignant if at least two\n",
    "        # annotations give it a malignancy score ‚â• 4 (scale usually 1‚Äì5).\n",
    "        is_malignant = len([a.malignancy for a in ann_cluster if a.malignancy >= 4])>=2 # Malignancy criterion\n",
    "        # Take the average along axis 0 (i.e., across rows, column-by-column).\n",
    "        centroid = numpy.mean([a.centroid for a in ann_cluster], axis=0)\n",
    "        bbox = numpy.mean([a.bbox_matrix() for a in ann_cluster], 0).T\n",
    "        coord = x.TransformIndexToPhysicalPoint([int(numpy.round(i)) for i in centroid[[1, 0, 2]]])\n",
    "        bbox_low = x.TransformIndexToPhysicalPoint([int(numpy.round(i)) for i in bbox[0, [1, 0, 2]]])\n",
    "        bbox_high = x.TransformIndexToPhysicalPoint([int(numpy.round(i)) for i in bbox[1, [1, 0, 2]]])\n",
    "        malignancy_data.append((suid, coord[0], coord[1], coord[2], bbox_low[0], bbox_low[1], bbox_low[2], bbox_high[0], bbox_high[1], bbox_high[2], is_malignant, [a.malignancy for a in ann_cluster]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check how many `mhd`s you are missing. It seems that the LUNA data has dropped a couple. Don't worry if there are <10 missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing scan UIDs.\n"
     ]
    }
   ],
   "source": [
    "if missing:\n",
    "  print(\"Missing scan UIDs:\")\n",
    "  for i, uid in enumerate(missing, 1):\n",
    "    print(f\"{i:2d}. {uid}\")\n",
    "else:\n",
    "  print(\"No missing scan UIDs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we match the malignancy data to the annotations. This is a lot faster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 601/601 [00:00<00:00, 638.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a structured DataFrame from a list of data records called malignancy_data\n",
    "df_mal = pandas.DataFrame(malignancy_data, columns=['seriesuid', 'coordX', 'coordY', 'coordZ', 'bboxLowX', 'bboxLowY', 'bboxLowZ', 'bboxHighX', 'bboxHighY', 'bboxHighZ', 'mal_bool', 'mal_details'])\n",
    "\n",
    "processed_annot = []\n",
    "annotations['mal_bool'] = float('nan')\n",
    "annotations['mal_details'] = [[] for _ in annotations.iterrows()]\n",
    "bbox_keys = ['bboxLowX', 'bboxLowY', 'bboxLowZ', 'bboxHighX', 'bboxHighY', 'bboxHighZ']\n",
    "for k in bbox_keys:\n",
    "    annotations[k] = float('nan')\n",
    "for series_id in tqdm.tqdm(annotations.seriesuid.unique()):\n",
    "    # series_id = '1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222365663678666836860'\n",
    "    # c = candidates[candidates.seriesuid == series_id]\n",
    "    a = annotations[annotations.seriesuid == series_id]\n",
    "    m = df_mal[df_mal.seriesuid == series_id]\n",
    "    if len(m) > 0:\n",
    "        m_ctrs = m[['coordX', 'coordY', 'coordZ']].values\n",
    "        a_ctrs = a[['coordX', 'coordY', 'coordZ']].values\n",
    "        #print(m_ctrs.shape, a_ctrs.shape)\n",
    "        matches = (numpy.linalg.norm(a_ctrs[:, None] - m_ctrs[None], ord=2, axis=-1) / a.diameter_mm.values[:, None] < 0.5)\n",
    "        has_match = matches.max(-1)\n",
    "        match_idx = matches.argmax(-1)[has_match]\n",
    "        a_matched = a[has_match].copy()\n",
    "        # c_matched['diameter_mm'] = a.diameter_mm.values[match_idx]\n",
    "        a_matched['mal_bool'] = m.mal_bool.values[match_idx]\n",
    "        a_matched['mal_details'] = m.mal_details.values[match_idx]\n",
    "        for k in bbox_keys:\n",
    "            a_matched[k] = m[k].values[match_idx]\n",
    "        processed_annot.append(a_matched)\n",
    "        processed_annot.append(a[~has_match])\n",
    "    else:\n",
    "        processed_annot.append(c)\n",
    "processed_annot = pandas.concat(processed_annot)\n",
    "processed_annot.sort_values('mal_bool', ascending=False, inplace=True)\n",
    "processed_annot['len_mal_details'] = processed_annot.mal_details.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we drop NAs (where we didn't find a match) and save it in the right place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nona = processed_annot.dropna()\n",
    "df_nona.to_csv('./data/part2/luna/annotations_with_malignancy.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
